{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tracking: databricks\n",
      "experiment: <Experiment: artifact_location='dbfs:/databricks/mlflow-tracking/3998396881915768', creation_time=1761273605949, experiment_id='3998396881915768', last_update_time=1761590368439, lifecycle_stage='active', name='/Users/esteban.berumen@iteso.mx/nyc-taxi-experiments', tags={'mlflow.experiment.sourceName': '/Users/esteban.berumen@iteso.mx/nyc-taxi-experiments',\n",
      " 'mlflow.experimentKind': 'custom_model_development',\n",
      " 'mlflow.experimentType': 'MLFLOW_EXPERIMENT',\n",
      " 'mlflow.ownerEmail': 'esteban.berumen@iteso.mx',\n",
      " 'mlflow.ownerId': '4857186035421233'}>\n"
     ]
    }
   ],
   "source": [
    "import os, mlflow\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv(override=True)  # Carga las variables del archivo .env\n",
    "EXPERIMENT_NAME = \"/Users/esteban.berumen@iteso.mx/nyc-taxi-experiments\"\n",
    "\n",
    "mlflow.set_tracking_uri(\"databricks\")\n",
    "experiment = mlflow.set_experiment(experiment_name=EXPERIMENT_NAME)\n",
    "print(\"tracking:\", mlflow.get_tracking_uri())\n",
    "print(\"experiment:\", experiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import root_mean_squared_error\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "\n",
    "DATA_DIR = \"../data\"  # ajusta si tu estructura difiere"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(46307, 22) (44218, 22)\n"
     ]
    }
   ],
   "source": [
    "def read_dataframe(filename):\n",
    "    df = pd.read_parquet(filename)\n",
    "\n",
    "    df['duration'] = df.lpep_dropoff_datetime - df.lpep_pickup_datetime\n",
    "    df.duration = df.duration.apply(lambda td: td.total_seconds() / 60)\n",
    "\n",
    "    df = df[(df.duration >= 1) & (df.duration <= 60)]\n",
    "\n",
    "    categorical = ['PULocationID', 'DOLocationID']\n",
    "    df[categorical] = df[categorical].astype(str)\n",
    "\n",
    "    return df\n",
    "\n",
    "df_train = read_dataframe(os.path.join(DATA_DIR, 'green_tripdata_2025-01.parquet'))\n",
    "df_val   = read_dataframe(os.path.join(DATA_DIR, 'green_tripdata_2025-02.parquet'))\n",
    "print(df_train.shape, df_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(46307, 4159) (44218, 4159)\n"
     ]
    }
   ],
   "source": [
    "def preprocess(df, dv):\n",
    "    df = df.copy()\n",
    "    df['PU_DO'] = df['PULocationID'] + '_' + df['DOLocationID']\n",
    "    categorical = ['PU_DO']\n",
    "    numerical = ['trip_distance']\n",
    "    records = df[categorical + numerical].to_dict(orient='records')\n",
    "    return dv.transform(records)\n",
    "\n",
    "df_train = df_train.copy()\n",
    "df_train['PU_DO'] = df_train['PULocationID'] + '_' + df_train['DOLocationID']\n",
    "categorical = ['PU_DO']\n",
    "numerical = ['trip_distance']\n",
    "dv = DictVectorizer()\n",
    "\n",
    "train_dicts = df_train[categorical + numerical].to_dict(orient='records')\n",
    "X_train = dv.fit_transform(train_dicts)\n",
    "X_val   = preprocess(df_val, dv)\n",
    "\n",
    "target = 'duration'\n",
    "y_train = df_train[target].values\n",
    "y_val   = df_val[target].values\n",
    "print(X_train.shape, X_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import optuna\n",
    "from optuna.samplers import TPESampler\n",
    "from mlflow.models.signature import infer_signature\n",
    "from sklearn.ensemble import GradientBoostingRegressor, RandomForestRegressor\n",
    "\n",
    "mlflow.sklearn.autolog(log_models=False)\n",
    "\n",
    "# Utilidades comunes\n",
    "def make_input_example(X_sparse, dv, n=5):\n",
    "    arr = X_sparse[:n].toarray() if hasattr(X_sparse, \"toarray\") else np.asarray(X_sparse[:n])\n",
    "    cols = dv.get_feature_names_out()\n",
    "    return pd.DataFrame(arr, columns=cols)\n",
    "\n",
    "def log_preprocessor(dv, artifact_dir=\"preprocessor\"):\n",
    "    os.makedirs(artifact_dir, exist_ok=True)\n",
    "    with open(os.path.join(artifact_dir, \"preprocessor.b\"), \"wb\") as f_out:\n",
    "        pickle.dump(dv, f_out)\n",
    "    mlflow.log_artifact(os.path.join(artifact_dir, \"preprocessor.b\"), artifact_path=\"preprocessor\")\n",
    "\n",
    "def rmse_for(model, X, y):\n",
    "    y_hat = model.predict(X)\n",
    "    return float(root_mean_squared_error(y, y_hat))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parent 1: Gradient Boosting (Optuna)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-10-27 13:17:41,811] A new study created in memory with name: no-name-44335e74-2d2f-4049-8971-c76e3d081638\n"
     ]
    }
   ],
   "source": [
    "# ========= Gradient Boosting (Optuna) CORREGIDO =========\n",
    "def objective_gbr(trial: optuna.trial.Trial):\n",
    "    params = {\n",
    "        \"n_estimators\": trial.suggest_int(\"n_estimators\", 100, 120),\n",
    "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 1e-3, 0.5, log=True),\n",
    "        \"max_depth\": trial.suggest_int(\"max_depth\", 2, 4),\n",
    "        \"subsample\": trial.suggest_float(\"subsample\", 0.7, 1.0),\n",
    "        \"random_state\": 42,\n",
    "    }\n",
    "\n",
    "    with mlflow.start_run(nested=True):\n",
    "        mlflow.set_tag(\"model_family\", \"gradient_boosting\")\n",
    "        mlflow.log_params(params)\n",
    "\n",
    "        # Densificar y mantener nombres de columnas (evita el warning)\n",
    "        cols = dv.get_feature_names_out()\n",
    "        Xtr = pd.DataFrame(X_train.toarray(), columns=cols)\n",
    "        Xva = pd.DataFrame(X_val.toarray(),   columns=cols)\n",
    "\n",
    "        model = GradientBoostingRegressor(**params)\n",
    "        model.fit(Xtr, y_train)\n",
    "        rmse = rmse_for(model, Xva, y_val)\n",
    "        mlflow.log_metric(\"rmse\", rmse)\n",
    "\n",
    "        # Input example y signature consistentes (DataFrame con columnas)\n",
    "        input_example = Xva.head(5)\n",
    "        signature = infer_signature(input_example, model.predict(input_example))\n",
    "\n",
    "        log_preprocessor(dv)\n",
    "        mlflow.sklearn.log_model(\n",
    "            sk_model=model,\n",
    "            name=\"model\",  # <-- en lugar de artifact_path\n",
    "            input_example=input_example,\n",
    "            signature=signature\n",
    "        )\n",
    "    return rmse\n",
    "\n",
    "sampler = TPESampler(seed=42)\n",
    "study_gbr = optuna.create_study(direction=\"minimize\", sampler=sampler)\n",
    "with mlflow.start_run(run_name=\"Parent: GradientBoosting (Optuna)\"):\n",
    "    study_gbr.optimize(objective_gbr, n_trials=15)  # si quieres, agrega timeout=\n",
    "    mlflow.log_params({f\"best_{k}\": v for k, v in study_gbr.best_params.items()})\n",
    "    mlflow.log_metric(\"best_rmse\", study_gbr.best_value)\n",
    "print(\"GBR best RMSE:\", study_gbr.best_value)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parent 2: Random Forest (Optuna)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========= Random Forest (Optuna) CORREGIDO =========\n",
    "def objective_rf(trial: optuna.trial.Trial):\n",
    "    params = {\n",
    "        \"n_estimators\": trial.suggest_int(\"n_estimators\", 200, 250),\n",
    "        \"max_depth\": trial.suggest_int(\"max_depth\", 5, 40),\n",
    "        \"min_samples_split\": trial.suggest_int(\"min_samples_split\", 2, 20),\n",
    "        \"min_samples_leaf\": trial.suggest_int(\"min_samples_leaf\", 1, 10),\n",
    "        \"max_features\": trial.suggest_categorical(\"max_features\", [\"sqrt\", \"log2\", None]),\n",
    "        \"random_state\": 42,\n",
    "        \"n_jobs\": -1,\n",
    "    }\n",
    "\n",
    "    with mlflow.start_run(nested=True):\n",
    "        mlflow.set_tag(\"model_family\", \"random_forest\")\n",
    "        mlflow.log_params(params)\n",
    "\n",
    "        # RF: tambi√©n en DataFrame con columnas para total consistencia\n",
    "        cols = dv.get_feature_names_out()\n",
    "        Xtr = pd.DataFrame(X_train.toarray(), columns=cols)\n",
    "        Xva = pd.DataFrame(X_val.toarray(),   columns=cols)\n",
    "\n",
    "        model = RandomForestRegressor(**params)\n",
    "        model.fit(Xtr, y_train)\n",
    "        rmse = rmse_for(model, Xva, y_val)\n",
    "        mlflow.log_metric(\"rmse\", rmse)\n",
    "\n",
    "        input_example = Xva.head(5)\n",
    "        signature = infer_signature(input_example, model.predict(input_example))\n",
    "\n",
    "        log_preprocessor(dv)\n",
    "        mlflow.sklearn.log_model(\n",
    "            sk_model=model,\n",
    "            name=\"model\",  # <-- en lugar de artifact_path\n",
    "            input_example=input_example,\n",
    "            signature=signature\n",
    "        )\n",
    "    return rmse\n",
    "\n",
    "sampler2 = TPESampler(seed=42)\n",
    "study_rf = optuna.create_study(direction=\"minimize\", sampler=sampler2)\n",
    "with mlflow.start_run(run_name=\"Parent: RandomForest (Optuna)\"):\n",
    "    study_rf.optimize(objective_rf, n_trials=15)  # si quieres, agrega timeout=\n",
    "    mlflow.log_params({f\"best_{k}\": v for k, v in study_rf.best_params.items()})\n",
    "    mlflow.log_metric(\"best_rmse\", study_rf.best_value)\n",
    "print(\"RF best RMSE:\", study_rf.best_value)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selecci√≥n de Challenger (mejor RMSE global) y registro en Model Registry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlflow import MlflowClient\n",
    "\n",
    "model_registry_name = \"time_series.default.nyc-taxi-model\"  # mismo modelo del proyecto\n",
    "\n",
    "# Buscar el mejor run global por RMSE entre ambos parents dentro del experimento\n",
    "runs = mlflow.search_runs(\n",
    "    experiment_names=[EXPERIMENT_NAME],\n",
    "    filter_string=\"\",\n",
    "    order_by=[\"metrics.rmse ASC\"],\n",
    "    output_format=\"list\"\n",
    ")\n",
    "assert len(runs) > 0, \"No se encontraron runs con m√©trica RMSE\"\n",
    "best_run = runs[0]\n",
    "print(\"\\nüèÜ Challenger candidate:\")\n",
    "print(\"Run ID:\", best_run.info.run_id)\n",
    "print(\"RMSE:\", best_run.data.metrics.get(\"rmse\"))\n",
    "print(\"Tags:\", best_run.data.tags)\n",
    "\n",
    "# Registrar el modelo del mejor run como nueva versi√≥n\n",
    "result = mlflow.register_model(\n",
    "    model_uri=f\"runs:/{best_run.info.run_id}/model\",\n",
    "    name=model_registry_name\n",
    ")\n",
    "print(\"Registered as version:\", result.version)\n",
    "\n",
    "client = MlflowClient()\n",
    "\n",
    "# Asignar alias 'challenger'\n",
    "client.set_registered_model_alias(\n",
    "    name=model_registry_name,\n",
    "    alias=\"challenger\",\n",
    "    version=result.version\n",
    ")\n",
    "\n",
    "# Documentar\n",
    "client.update_model_version(\n",
    "    name=model_registry_name,\n",
    "    version=result.version,\n",
    "    description=f\"Challenger registrado desde run {best_run.info.run_id} con RMSE={best_run.data.metrics.get('rmse')} el {datetime.today()}\"\n",
    ")\n",
    "print(\"Alias 'challenger' actualizado a la versi√≥n\", result.version)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluaci√≥n en Marzo 2025: Champion vs Challenger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aseg√∫rate de colocar el archivo en ../data/green_tripdata_2025-03.parquet\n",
    "df_mar = read_dataframe(os.path.join(DATA_DIR, 'green_tripdata_2025-03.parquet'))\n",
    "X_mar  = preprocess(df_mar, dv)\n",
    "y_mar  = df_mar[target].values\n",
    "input_example_mar = make_input_example(X_mar, dv)\n",
    "print(df_mar.shape, X_mar.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow.pyfunc\n",
    "\n",
    "champion_uri   = f\"models:/{model_registry_name}@Champion\"\n",
    "challenger_uri = f\"models:/{model_registry_name}@Challenger\"\n",
    "\n",
    "print(\"Loading Champion:\", champion_uri)\n",
    "print(\"Loading Challenger:\", challenger_uri)\n",
    "\n",
    "champion = mlflow.pyfunc.load_model(champion_uri)\n",
    "challenger = mlflow.pyfunc.load_model(challenger_uri)\n",
    "\n",
    "# Algunos modelos registrados con sklearn pueden requerir arrays densos\n",
    "X_mar_dense = X_mar.toarray() if hasattr(X_mar, \"toarray\") else X_mar\n",
    "\n",
    "yhat_champion   = champion.predict(input_example_mar)\n",
    "yhat_challenger = challenger.predict(input_example_mar)\n",
    "\n",
    "# Para la m√©trica real usamos todo el set de marzo\n",
    "yhat_c_full = champion.predict(X_mar_dense)\n",
    "yhat_n_full = challenger.predict(X_mar_dense)\n",
    "\n",
    "rmse_champion   = float(root_mean_squared_error(y_mar, yhat_c_full))\n",
    "rmse_challenger = float(root_mean_squared_error(y_mar, yhat_n_full))\n",
    "\n",
    "print({\n",
    "    \"rmse_champion\": rmse_champion,\n",
    "    \"rmse_challenger\": rmse_challenger\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decisi√≥n de promoci√≥n autom√°tica (opcional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROMOTION_DELTA = 0.05  # mejora m√≠nima absoluta en RMSE (minutos)\n",
    "\n",
    "promote = (rmse_challenger <= rmse_champion - PROMOTION_DELTA)\n",
    "print(\"Candidato a promover a Champion?\", promote)\n",
    "\n",
    "if promote:\n",
    "    # Obtener versi√≥n apuntada por 'challenger'\n",
    "    model = client.get_registered_model(model_registry_name)\n",
    "    # Buscar la versi√≥n por alias\n",
    "    versions = client.search_model_versions(f\"name='{model_registry_name}'\")\n",
    "    challenger_version = None\n",
    "    for v in versions:\n",
    "        aliases = set(getattr(v, 'aliases', []) or [])\n",
    "        if 'challenger' in aliases:\n",
    "            challenger_version = v.version\n",
    "            break\n",
    "    assert challenger_version is not None, \"No se encontr√≥ versi√≥n con alias 'challenger'\"\n",
    "\n",
    "    # Mover alias 'Champion' a la versi√≥n challenger\n",
    "    client.set_registered_model_alias(\n",
    "        name=model_registry_name,\n",
    "        alias=\"Champion\",\n",
    "        version=challenger_version\n",
    "    )\n",
    "\n",
    "    client.update_model_version(\n",
    "        name=model_registry_name,\n",
    "        version=challenger_version,\n",
    "        description=(\n",
    "            f\"Promovido a Champion el {datetime.today()} tras evaluaci√≥n en marzo 2025. \"\n",
    "            f\"RMSE Champion previo: {rmse_champion:.4f}, RMSE Challenger: {rmse_challenger:.4f}.\"\n",
    "        )\n",
    "    )\n",
    "    print(f\"‚úî Alias 'Champion' ahora apunta a la versi√≥n {challenger_version}\")\n",
    "else:\n",
    "    print(\"‚ùå No se promueve: ganancia insuficiente seg√∫n criterio actual.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evidencia para el PR\n",
    "- Prints de `run_id`, `rmse`, versi√≥n registrada y aliases.\n",
    "- Diccionario con RMSE de Champion vs Challenger en marzo.\n",
    "- Decisi√≥n (y, si aplica, confirmaci√≥n de movimiento de alias)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nyc-taxi-predictions-2025",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
